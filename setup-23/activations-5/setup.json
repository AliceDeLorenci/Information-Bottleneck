{
"comments": "original paper setup but with weight decay [mini-batch][smaller lr]",
"dataset": "synthetic",
"train_ratio": 0.85,
"hidden_dims": [
12,
10,
7,
5,
4,
3,
2
],
"output_dim": 1,
"hidden_activation": "tanh",
"output_activation": "sigmoid",
"lr": 0.001,
"momentum": 0.9,
"weight_decay": 0.0001,
"optimizer": "lambda parameters: torch.optim.SGD( parameters, lr=setup[\"lr\"], momentum=setup[\"momentum\"], weight_decay=setup[\"weight_decay\"] )\n",
"n_epochs": 10000,
"batch_size": 256,
"loss_function": "lambda output, target, reduction='mean': torch.nn.functional.binary_cross_entropy(output.reshape(-1), target.float(), reduction=reduction)\n",
"evaluate_correct": "lambda output, target: torch.sum( torch.round(output.reshape(-1)) == target, dtype=torch.float32 )\n",
"shuffle": true,
"warmup": true,
"seed": 275,
"setup_idx": 23,
"verbose": 0,
"subdir": 5,
"temporize": false
}