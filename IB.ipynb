{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install numpy torch torchvision matplotlib scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose torch device\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    \n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataset\n",
    "from dataset import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MI Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mi\n",
    "from mi import *    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nn\n",
    "from nn import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(dataset)\n",
    "importlib.reload(mi)\n",
    "importlib.reload(nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = buildDatasets( *loadMNISTData(root=\"data\"), ratio=6/7, name=\"mnist\" )\n",
    "dataset = buildDatasets( *loadSyntheticData(file=\"data/synthetic/var_u.mat\"), name=\"synthetic\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( \"Number of samples in the training set:\", len(dataset[\"train\"]) )\n",
    "print( \"Number of samples in the test set:\", len(dataset[\"test\"]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SETTING 1\n",
    "# - Synthetic dataset\n",
    "# - Test accuracy: 0.9426\n",
    "\n",
    "setup = dict()\n",
    "# network parameters\n",
    "setup[\"hidden_dims\"] = [10, 7, 5, 4, 3]                         \n",
    "setup[\"output_dim\"] = 1                                         \n",
    "setup[\"hidden_activation_f\"] = lambda input: F.tanh(input)      \n",
    "setup[\"output_activation_f\"] = lambda input: F.sigmoid(input)   \n",
    "\n",
    "# optimizer\n",
    "setup[\"lr\"] = 0.01                             \n",
    "setup[\"momentum\"] = 0.9\n",
    "setup[\"optimizer\"] = lambda parameters: torch.optim.SGD( parameters, lr=setup[\"lr\"], momentum=setup[\"momentum\"] )\n",
    "\n",
    "# training configuration\n",
    "setup[\"n_epochs\"] = 10000\n",
    "setup[\"batch_size\"] = None\n",
    "setup[\"loss_function\"] = lambda output, target, reduction='mean': F.binary_cross_entropy(output.reshape(-1), target.float(), reduction=reduction)\n",
    "setup[\"evaluate_correct\"] = lambda output, target: torch.sum( torch.round(output.reshape(-1)) == target, dtype=torch.float32 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SETTING 2\n",
    "# - MNIST\n",
    "# - Test accuracy: 0.9027\n",
    "\n",
    "setup = dict()\n",
    "# network parameters\n",
    "setup[\"hidden_dims\"] = [256, 256, 128]                                          # hidden layers sizes\n",
    "setup[\"output_dim\"] = 10                                                        # output layer size\n",
    "setup[\"hidden_activation_f\"] = lambda input: F.tanh(input)                      # activation function for the hidden layers\n",
    "setup[\"output_activation_f\"] = lambda input: F.log_softmax( input, dim=1 )      # activation function for the output layer\n",
    "\n",
    "# optimizer\n",
    "setup[\"lr\"] = 0.01  \n",
    "setup[\"optimizer\"] = lambda parameters: torch.optim.Adam( parameters, lr=setup[\"lr\"] )       \n",
    "\n",
    "# training configuration\n",
    "setup[\"n_epochs\"] = 20\n",
    "setup[\"batch_size\"] = None\n",
    "setup[\"loss_function\"] = lambda output, target, reduction='mean': F.nll_loss(output, target, reduction=reduction)\n",
    "setup[\"evaluate_correct\"] = lambda output, target: torch.sum( output.argmax(dim=1) == target, dtype=torch.float32 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = buildDataLoader(dataset, batch_size=setup[\"batch_size\"])\n",
    "# batch = next( iter( loader[\"train\"] ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save = True\n",
    "save_interval = 1\n",
    "\n",
    "model = Network(\n",
    "            input_dim=dataset[\"n_features\"], \n",
    "            hidden_dims=setup[\"hidden_dims\"],\n",
    "            output_dim=setup[\"output_dim\"],\n",
    "            hidden_activation_f=setup[\"hidden_activation_f\"],\n",
    "            output_activation_f=setup[\"output_activation_f\"]\n",
    "        ).to(device)\n",
    "\n",
    "optimizer = setup[\"optimizer\"]( model.parameters() )\n",
    "\n",
    "if save:\n",
    "        folder = save_setup(dataset, setup)\n",
    "\n",
    "for epoch in range(1, setup[\"n_epochs\"] + 1):\n",
    "        train(model, setup, loader[\"train\"], optimizer, device, epoch, verbose=2)\n",
    "        test(model, setup, loader[\"test\"], device)\n",
    "        if save and epoch%save_interval == 0:\n",
    "                save_activations(model, dataset[\"full\"], epoch, folder, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mi_xt_epochs, mi_ty_epochs, epochs = compute_mi(dataset[\"full\"], folder, interval=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save MI results as compressed numpy file\n",
    "path = \"./save/\"\n",
    "np.savez_compressed( path+folder+\"/mi\", mi_xt_epochs=mi_xt_epochs, mi_ty_epochs=mi_ty_epochs, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load results\n",
    "loaded_results = np.load( path+folder+\"/mi.npz\" )\n",
    "loaded_mi_xt_epochs = loaded_results[\"mi_xt_epochs\"]\n",
    "loaded_mi_ty_epochs = loaded_results[\"mi_ty_epochs\"]\n",
    "loaded_epochs = loaded_results[\"epochs\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_info_plan(mi_xt_epochs, mi_ty_epochs, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
